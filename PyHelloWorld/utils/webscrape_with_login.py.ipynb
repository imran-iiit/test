{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_url(): \n",
      "[Cookie(version=0, name='csrftoken', value='q5MtzS0DHI2NxrBXhtzB1jWS3WE8mjew', port=None, port_specified=False, domain='www.screener.in', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=True, expires=1745527064, discard=False, comment=None, comment_url=None, rest={'SameSite': 'Lax'}, rfc2109=False)]\n",
      "The value of csrfMiddlewareToken is: AmHGE21z5lOeARI5HDLKOndOGDUCN4jLQhjZ3KR2CTGRX89SOWabFwZwzpoAZdn7\"\n",
      "\n",
      "\n",
      "<class 'urllib.error.HTTPError'>\n",
      "()\n",
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'response' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m requestHeaderL \u001b[38;5;241m=\u001b[39m{ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferer\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.screener.in/login/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.screener.in\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnection\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep-alive\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec-fetch-mode\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnavigate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec-fetch-site\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame-origin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msec-fetch-user\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?1\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     87\u001b[0m login_data \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode({ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsrfmiddlewaretoken\u001b[39m\u001b[38;5;124m'\u001b[39m : csrfMiddlewareToken, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreenerintest@gmail.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m91@Screener\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogin\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 88\u001b[0m code, headers, html, cur_opener, jar \u001b[38;5;241m=\u001b[39m \u001b[43mget_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.screener.in/login/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogin_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcur_opener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestHeader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequestHeaderL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value of respond headers is: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(headers)\n",
      "Cell \u001b[0;32mIn[8], line 62\u001b[0m, in \u001b[0;36mget_url\u001b[0;34m(url, data, timeout, opener, requestHeader, jar)\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28mprint\u001b[39m(inst)\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m jar\u001b[38;5;241m.\u001b[39mextract_cookies(\u001b[43mresponse\u001b[49m, request)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn get_url(): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(jar\u001b[38;5;241m.\u001b[39mmake_cookies(response, request))\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'response' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import http.cookiejar\n",
    "from datetime import datetime\n",
    "from calendar import timegm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HTTPRedirectHandler(urllib.request.HTTPRedirectHandler):\n",
    "    def __init__(self, jar):\n",
    "        self.jar = jar\n",
    "\n",
    "    def redirect_request(self, req, fp, code, msg, hds, newurl):\n",
    "\n",
    "        sessionid = ''\n",
    "        for i in hds._headers:\n",
    "            if i[0] != 'Set-Cookie':\n",
    "                continue\n",
    "            if i[1].startswith('sessionid='):\n",
    "                sessionid = i[1]\n",
    "                print(\"In redirect_request(): SessionId found value is: \" + sessionid + \"\\n\\n\")\n",
    "                break\n",
    "\n",
    "        newreq = super().redirect_request(\n",
    "            req, fp, code, msg, hds, newurl)\n",
    "\n",
    "\n",
    "        return newreq\n",
    "\n",
    "\n",
    "\n",
    "def get_url(url, data=None, timeout=30, opener=None, requestHeader = None, jar = None):\n",
    "  '''get_url accepts a URL string and return the server response code, response headers, and contents of the file'''\n",
    "\n",
    "  req_headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "  }\n",
    "\n",
    "  if requestHeader:\n",
    "      req_headers.update(requestHeader)\n",
    "\n",
    "  request = urllib.request.Request(url, headers=req_headers, data=data)\n",
    "  if not opener:\n",
    "    jar = http.cookiejar.CookieJar()\n",
    "    redirectHandler = HTTPRedirectHandler(jar)\n",
    "\n",
    "\n",
    "    opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(jar), redirectHandler)\n",
    "\n",
    "\n",
    "  while 1:\n",
    "    try:\n",
    "        response = opener.open(request)\n",
    "    except Exception as inst:\n",
    "        print(type(inst))\n",
    "        print(inst.args)\n",
    "        print(inst)\n",
    "\n",
    "    break\n",
    "\n",
    "  jar.extract_cookies(response, request)\n",
    "  print(\"In get_url(): \")\n",
    "  print(jar.make_cookies(response, request))\n",
    "\n",
    "  code = response.code\n",
    "  headers = response.headers\n",
    "  html = response.read()\n",
    "  return code, headers, html, opener, jar\n",
    "\n",
    "\n",
    "\n",
    "code, headers, html, cur_opener, jar = get_url('https://www.screener.in/login/', timeout=3)\n",
    "\n",
    "#responceHeaders = headers['Set-Cookie']\n",
    "#responceHeaders = responceHeaders[responceHeaders.find('=') + 1:responceHeaders.find(';')]\n",
    "#print(responceHeaders)\n",
    "#print(headers)\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "fdata = soup.find_all('input', {'name': \"csrfmiddlewaretoken\"})\n",
    "csrfMiddlewareToken = str(fdata[0])\n",
    "csrfMiddlewareToken = csrfMiddlewareToken[csrfMiddlewareToken.find('value=\"') + len('value=\"') : csrfMiddlewareToken.find('>') -1]\n",
    "print(\"The value of csrfMiddlewareToken is: \" + csrfMiddlewareToken + \"\\n\\n\")\n",
    "requestHeaderL ={ 'referer' : 'https://www.screener.in/login/', 'origin' : 'https://www.screener.in', 'Connection' : \"keep-alive\", 'sec-fetch-mode': 'navigate', 'sec-fetch-site': 'same-origin', 'sec-fetch-user': '?1'}\n",
    "\n",
    "login_data = urllib.parse.urlencode({ 'csrfmiddlewaretoken' : csrfMiddlewareToken, 'next': '', 'username' : \"screenerintest@gmail.com\", 'password' : \"91@Screener\", 'action' : 'login'}).encode('UTF-8') \n",
    "code, headers, html, cur_opener, jar = get_url('https://www.screener.in/login/', data=login_data, timeout=3, opener= cur_opener, requestHeader=requestHeaderL, jar=jar)\n",
    "print(\"The value of respond headers is: \")\n",
    "print(headers)\n",
    "\n",
    "code, headers, html, cur_opener, jar = get_url('https://www.screener.in/company/BHARATRAS/',timeout=3, opener= cur_opener, requestHeader=requestHeaderL, jar= jar)\n",
    "soup= BeautifulSoup(html,'html.parser')\n",
    "fdata = soup.find_all('li')\n",
    "print(fdata)\n",
    "\n",
    "# for i in fdata:\n",
    "#     strVal = i.get_text().replace('\\n','').strip()\n",
    "#     val = strVal[0:strVal.find(':')].strip()\n",
    "#     if val != 'PEG Ratio':\n",
    "#         continue\n",
    "#     else:\n",
    "#         print('\\nPEG Ratio found\\n')\n",
    "#         break;\n",
    "# else:\n",
    "#     print('\\nPEG Ratio not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "Market Cap\n",
      "Current Price\n",
      "High / Low\n",
      "Stock P/E\n",
      "Book Value\n",
      "Dividend Yield\n",
      "ROCE\n",
      "ROE\n",
      "Face Value\n",
      "ROIC\n",
      "PEG Ratio\n",
      "Debt to equity\n",
      "Financial leverage\n",
      "EVEBITDA\n",
      "Pledged percentage\n",
      "CMP / FCF\n",
      "Market Cap        58954.00\n",
      "Current Price       506.00\n",
      "High / Low          680.00\n",
      "Stock P/E            52.10\n",
      "Book Value           41.50\n",
      "Dividend Yield        0.53\n",
      "ROCE                 23.80\n",
      "ROE                  20.40\n",
      "Face Value            1.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SCREENER_TOP_DATA = ['Market Cap', 'Current Price', 'High / Low', 'Stock P/E', 'Book Value',\n",
    "                     'Dividend Yield', 'ROCE', 'ROE', 'Face Value', 'ROIC', 'PEG Ratio',\n",
    "                     'Debt to equity', 'Financial leverage', 'EVEBITDA', 'Pledged percentage',\n",
    "                     'CMP / FCF']\n",
    "\n",
    "def fetch_number_span(list_element):\n",
    "    num_span = list_element.find('span',{'class':'number'})\n",
    "\n",
    "    num_span = num_span.text.replace(',', '')\n",
    "    return float(num_span) if (num_span != '') else 0.0\n",
    "    \n",
    "def extract_scrip_ratios(soup,div_class, ul_id):\n",
    "    div_html = soup.find('div',{'class': div_class})\n",
    "    ul_html = div_html.find('ul',{'id': ul_id})\n",
    "     \n",
    "    scrip_data = pd.Series()\n",
    "    for d in SCREENER_TOP_DATA:\n",
    "        print(d)\n",
    "        for li in ul_html.find_all(\"li\"):\n",
    "            name_span = li.find('span',{'class':'name'})\n",
    "            \n",
    "            if d in name_span.text: \n",
    "                scrip_data[d] = fetch_number_span(li)\n",
    "\n",
    "    return scrip_data\n",
    "\n",
    "login_url = 'https://www.screener.in/login/'\n",
    "data = {\n",
    "    'id_username': 'shaik.imran@gmail.com',\n",
    "    'id_password': 'iiit123'\n",
    "}\n",
    "\n",
    "with requests.Session() as s:\n",
    "    response = s.post(login_url , data)\n",
    "    print(response.status_code) # 403 - Forbidden\n",
    "#     index_page = s.get('https://www.screener.in/company/BERGEPAINT/consolidated/')\n",
    "#     soup = BeautifulSoup(index_page.text, 'html.parser')\n",
    "#     scrip_data = extract_scrip_ratios(soup,'company-ratios', 'top-ratios')\n",
    "#     print(scrip_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Market Cap\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       "     \n",
       "       ₹\n",
       "     \n",
       "     <span class=\"number\">58,954</span>\n",
       "     \n",
       "       Cr.\n",
       "     \n",
       "   </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Current Price\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       "     \n",
       "       ₹\n",
       "     \n",
       "     <span class=\"number\">506</span>\n",
       " </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     High / Low\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">₹ <span class=\"number\">680</span> / <span class=\"number\">496</span></span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Stock P/E\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       " <span class=\"number\">52.1</span>\n",
       " </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Book Value\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       "     \n",
       "       ₹\n",
       "     \n",
       "     <span class=\"number\">41.5</span>\n",
       " </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Dividend Yield\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       " <span class=\"number\">0.53</span>\n",
       "     \n",
       "       %\n",
       "     \n",
       "   </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     ROCE\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       " <span class=\"number\">23.8</span>\n",
       "     \n",
       "       %\n",
       "     \n",
       "   </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     ROE\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       " <span class=\"number\">20.4</span>\n",
       "     \n",
       "       %\n",
       "     \n",
       "   </span>\n",
       " </li>,\n",
       " <li class=\"flex flex-space-between\" data-source=\"default\">\n",
       " <span class=\"name\">\n",
       "     \n",
       "     Face Value\n",
       "     \n",
       "   </span>\n",
       " <span class=\"nowrap value\">\n",
       "     \n",
       "       ₹\n",
       "     \n",
       "     <span class=\"number\">1.00</span>\n",
       " </span>\n",
       " </li>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_class, ul_id = 'company-ratios', 'top-ratios'\n",
    "div_html = soup.find('div',{'class': div_class})\n",
    "ul_html = div_html.find('ul',{'id': ul_id})\n",
    "ul_html.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "login_url = 'https://www.screener.in/login/'\n",
    "payload = {'user_id': 'shaik.imran@gmail.com', 'password': 'iiit123'} \n",
    "session = requests.Session() # save an instance of request.Session \n",
    "req = session.post(login_url, data=payload, verify=False) \n",
    " \n",
    "data = session.get('https://www.screener.in/company/BERGEPAINT/consolidated/') # should not redirect you to the login page \n",
    "\n",
    "# print(dir(data))\n",
    "soup = BeautifulSoup(data.text, 'html.parser')\n",
    "\n",
    "# page=urlopen(req)\n",
    "# soup = BeautifulSoup(page)\n",
    "scrip_data = extract_scrip_ratios(soup,'company-ratios', 'top-ratios')\n",
    "print(scrip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# from web_commons import extract_table_by_class, flatten_df, extract_compound_tables\n",
    "# from web_commons import fetch_scrip_data, extract_scrip_ratios, get_screener_data\n",
    "# from commons import read_xls, get_stock_data, NSE_BSE, save_csv, get_holding_quantities\n",
    "# from consts import CONSOLIDATED_NOT_AVAILABLE_ON_SCREENER, OUT_DIR\n",
    "# from urllib.request import urlopen, Request\n",
    "\n",
    "SCREENER_TOP_DATA = ['Market Cap', 'Current Price', 'High / Low', 'Stock P/E', 'Book Value',\n",
    "                     'Dividend Yield', 'ROCE', 'ROE', 'Face Value', 'ROIC', 'PEG Ratio',\n",
    "                     'Debt to equity', 'Financial leverage', 'EVEBITDA', 'Pledged percentage',\n",
    "                     'CMP / FCF']\n",
    "\n",
    "def fetch_number_span(list_element):\n",
    "    num_span = list_element.find('span',{'class':'number'})\n",
    "\n",
    "    num_span = num_span.text.replace(',', '')\n",
    "    return float(num_span) if (num_span != '') else 0.0\n",
    "    \n",
    "def extract_scrip_ratios(soup,div_class, ul_id):\n",
    "    div_html = soup.find('div',{'class': div_class})\n",
    "    ul_html = div_html.find('ul',{'id': ul_id})\n",
    "     \n",
    "    scrip_data = pd.Series()\n",
    "    for d in SCREENER_TOP_DATA:\n",
    "        print(d)\n",
    "        for li in ul_html.find_all(\"li\"):\n",
    "            name_span = li.find('span',{'class':'name'})\n",
    "            \n",
    "            if d in name_span.text: \n",
    "                scrip_data[d] = fetch_number_span(li)\n",
    "\n",
    "    return scrip_data\n",
    "\n",
    "\n",
    "cookies = {\n",
    "    '_ga': 'GA1.2.1753029431.1611727839',\n",
    "    'csrftoken': 'ae5rUfn2PYjAxSIrAg32eZk37U7C2vyV',\n",
    "    'sessionid': '9tgnw2y6ievud7362gb83gri2qopwab9',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'www.screener.in',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'max-age=0',\n",
    "    # 'cookie': '_ga=GA1.2.1753029431.1611727839; csrftoken=ae5rUfn2PYjAxSIrAg32eZk37U7C2vyV; sessionid=9tgnw2y6ievud7362gb83gri2qopwab9',\n",
    "    'dnt': '1',\n",
    "    'referer': 'https://www.screener.in/company/RAJRATAN/consolidated/',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"116\", \"Not)A;Brand\";v=\"24\", \"Google Chrome\";v=\"116\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "response = requests.get('https://www.screener.in/company/BERGEPAINT/consolidated/', auth=('shaik.imran@gmail.com', 'iiit123'), cookies=cookies, headers=headers)\n",
    "# req = Request('https://www.screener.in/company/BERGEPAINT/consolidated/', cookies=cookies, headers=headers)\n",
    "# print(response.text)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# page=urlopen(req)\n",
    "# soup = BeautifulSoup(page)\n",
    "scrip_data = extract_scrip_ratios(soup,'company-ratios', 'top-ratios')\n",
    "print(scrip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import pandas as pd\n",
    "# from requests_html import HTMLSession\n",
    "\n",
    "CONSOLIDATED_NOT_AVAILABLE_ON_SCREENER = ['PRINCEPIPE', 'RELAXO']\n",
    "\n",
    "\n",
    "SCREENER_TOP_DATA = ['Market Cap', 'Current Price', 'High / Low', 'Stock P/E', 'Book Value',\n",
    "                     'Dividend Yield', 'ROCE', 'ROE', 'Face Value', 'ROIC', 'PEG Ratio',\n",
    "                     'Debt to equity', 'Financial leverage', 'EVEBITDA', 'Pledged percentage',\n",
    "                     'CMP / FCF']\n",
    "\n",
    "def fetch_number_span(list_element):\n",
    "    num_span = list_element.find('span',{'class':'number'})\n",
    "\n",
    "    num_span = num_span.text.replace(',', '')\n",
    "    return float(num_span) if (num_span != '') else 0.0\n",
    "    \n",
    "def extract_scrip_ratios(soup,div_class, ul_id):\n",
    "    div_html = soup.find('div',{'class': div_class})\n",
    "    ul_html = div_html.find('ul',{'id': ul_id})\n",
    "     \n",
    "    scrip_data = pd.Series()\n",
    "    for d in SCREENER_TOP_DATA:\n",
    "        print(d)\n",
    "        for li in ul_html.find_all(\"li\"):\n",
    "            name_span = li.find('span',{'class':'name'})\n",
    "            \n",
    "            if d in name_span.text: \n",
    "                scrip_data[d] = fetch_number_span(li)\n",
    "\n",
    "    return scrip_data\n",
    "\n",
    "# df['ROIC']\n",
    "scrip = 'BERGEPAINT'\n",
    "print(f'********** {scrip}')\n",
    "URL = f'https://www.screener.in/company/{scrip}/'\n",
    "\n",
    "login_url = 'https://www.screener.in/login/'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'csrfmiddlewaretoken': '',\n",
    "    'next': '/api/company/6596449/quick_ratios/',\n",
    "    'username': 'shaik.imran@gmail.com',\n",
    "    'password': 'iiit123',\n",
    "}\n",
    "\n",
    "if scrip not in CONSOLIDATED_NOT_AVAILABLE_ON_SCREENER:\n",
    "    URL += 'consolidated/'\n",
    "    \n",
    "# with requests.Session() as s:\n",
    "#     s.headers.update(headers)\n",
    "#     res = s.get(URL)\n",
    "#     soup = BeautifulSoup(res.text,\"lxml\")\n",
    "#     params['csrfmiddlewaretoken'] = soup.select_one(\"input[name='csrfmiddlewaretoken']\")['value']\n",
    "#     s.headers['Origin'] = 'https://www.screener.in'\n",
    "#     s.headers['Referer'] = 'https://www.screener.in/login/'\n",
    "#     resp = s.post(login_url,data=params)\n",
    "#     print(s.cookies.items())\n",
    "#     resp = s.post(URL,data=params)\n",
    "#     print(resp)\n",
    "\n",
    "with requests.Session() as s:\n",
    "    login_url = 'https://www.screener.in/login/'\n",
    "    USERNAME = \"shaik.imran@gmail.com\"\n",
    "    PASSWORD = \"iiit123\"\n",
    "\n",
    "    s.get(login_url)\n",
    "    csrftoken = s.cookies['csrftoken']\n",
    "    print(s.cookies.items())\n",
    "\n",
    "    login_data = dict(csrftoken=csrftoken, next='', username=USERNAME, password=PASSWORD)\n",
    "    s.post(login_url, data=login_data, headers={\"Referer\": \"https://www.screener.in/\"})\n",
    "\n",
    "    r = s.get(URL)\n",
    "#     r.html.render(timeout=10, sleep=10)\n",
    "#     print(r.text)\n",
    "    soup = BeautifulSoup(r.text,\"lxml\")\n",
    "    print(extract_scrip_ratios(soup,'company-ratios', 'top-ratios'))\n",
    "\n",
    "\n",
    "#     hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "# #     req = Request(URL, data=params)\n",
    "#     page= s.post(req, data=params)\n",
    "#     soup = BeautifulSoup(page)\n",
    "#     data = {'Scrip': scrip} \n",
    "#     data.update(extract_scrip_ratios(soup,'company-ratios', 'top-ratios'))\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "df = pd.read_html(\n",
    "    requests.get(\"https://www.screener.in/company/BERGEPAINT/consolidated/\").text,\n",
    "    flavor=\"bs4\",\n",
    ")\n",
    "\n",
    "# df.to_csv(\"last_table.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
